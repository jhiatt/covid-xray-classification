{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import sklearn\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import random as python_random\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "np.random.seed(42) # note that you must use the same seed to ensure consistentcy in your training/validation/testing\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "\n",
    "#### Questions:\n",
    "# How does tf (under this method) store labels? Can I access them?\n",
    "#    Look into how the resizing line is done\n",
    "# What happens if I don't pass the y value into imageDataGenerator().flow()?\n",
    "# is this enough work? (oversampling, data augmentation, adusting the prediction wieghts)\n",
    "# multiple expert -  3 different model (majority voting at the end to make predictions) - cost trade off for computing\n",
    "# - talk about costs (training time, different work, etc)\n",
    "# - accuracy vs tradeoffs (latency of making one prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the data above isn't run, run this\n",
    "\n",
    "data_path = \"../dl_data/\"\n",
    "class_names = os.listdir(data_path)\n",
    "class_dist = {}\n",
    "for c in class_names:\n",
    "    class_dist[c] = len(os.listdir(data_path + c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Covid_img', 'Viral_img', 'Normal_img']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10912 images belonging to 3 classes.\n",
      "Found 2726 images belonging to 3 classes.\n",
      "Found 1514 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files \n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.preprocessing import image\n",
    "\n",
    "#### calculate class weights\n",
    "\n",
    "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "# The sum of the weights of all examples stays the same.\n",
    "total = sum(class_dist.values())\n",
    "weight_for_0 = (1 / class_dist[class_names[0]]) * (total / 2.0)\n",
    "weight_for_1 = (1 / class_dist[class_names[1]]) * (total / 2.0)\n",
    "weight_for_2 = (1 / class_dist[class_names[2]]) * (total / 2.0)\n",
    "\n",
    "class_weights = {0: weight_for_0, 1: weight_for_1, 2: weight_for_2}\n",
    "\n",
    "# directories\n",
    "data_dir = \"../dl_data\"\n",
    "# test_dir = \"../test_data\"\n",
    "HOLD_dir = \"../HOLD_data\"\n",
    "\n",
    "\n",
    "#### save out augmented data for visualization\n",
    "\n",
    "# ## first delete any existing files\n",
    "# aug_dir = '../augmented_data'\n",
    "# aug_files = os.listdir(aug_dir)\n",
    "# for f in aug_files:\n",
    "#     os.remove(aug_dir + '/' + f)\n",
    "\n",
    "    \n",
    "batch_size = 32;\n",
    "# IMPORTANT: Depends on what pre-trained model you choose, you will need to change these dimensions accordingly\n",
    "img_height = 224; \n",
    "img_width = 224;\n",
    "    \n",
    "\n",
    "# data augmentation (for training only)\n",
    "train_data_gen = ImageDataGenerator(rescale=1./255,\n",
    "                                    zoom_range= 0.3, \n",
    "                                    horizontal_flip= True, \n",
    "                                    shear_range= 0.2,\n",
    "                                    rotation_range = 30,\n",
    "                                    validation_split=0.2\n",
    "\n",
    "                                    )\n",
    "\n",
    "\n",
    "\n",
    "train_ds = train_data_gen.flow_from_directory(\n",
    "    directory = data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    color_mode='rgb',\n",
    "    classes=None,\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    seed=42,\n",
    "#     save_to_dir=aug_dir,\n",
    "#     save_prefix='aug',\n",
    "#     save_format='png',\n",
    "    follow_links=False,\n",
    "    subset='training',\n",
    "    interpolation='nearest'\n",
    ")\n",
    "\n",
    "validation_ds = train_data_gen.flow_from_directory(\n",
    "    directory=data_dir,  # same directory because we are splitting the data here\n",
    "    follow_links=False,\n",
    "    subset='validation',\n",
    "    interpolation='nearest',\n",
    "    target_size=(img_height, img_width), \n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "    seed=42,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "class_ind = (train_ds.class_indices)\n",
    "\n",
    "test_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "# holdout data\n",
    "HOLD_ds = test_data_gen.flow_from_directory(directory=HOLD_dir, \n",
    "                                         target_size=(img_height, img_width), \n",
    "                                         class_mode='categorical',\n",
    "                                         shuffle=False,\n",
    "                                         seed=42,\n",
    "                                         batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Covid_img': 0, 'Normal_img': 1, 'Viral_img': 2}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_ind\n",
    "\n",
    "# scikitlearn funciton for recall/precision etc. scikitlearn.metrics\n",
    "#train on accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this is just a bug fix, hopefully I won't need to use it again.\n",
    "\n",
    "# fi = os.listdir(aug_dir + '/' + os.listdir(aug_dir)[0])\n",
    "# for f in fi:\n",
    "#     os.remove(aug_dir + '/' + os.listdir(aug_dir)[0] + '/' + f)\n",
    "\n",
    "# os.rmdir(aug_dir + '/' + os.listdir(aug_dir)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set checkpoint to resume training if it stops unexpectedly\n",
    "checkpoint_path = \"../checkpoints/training_ROUND3/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 12:51:12.512087: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-26 12:51:14.388443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38397 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "ds_size_1 = (224, 224)\n",
    "# train_ds_1 = train_ds.map(lambda image, label: (tf.image.resize(image, ds_size_1), label))\n",
    "# validation_ds_1 = validation_ds.map(lambda image, label: (tf.image.resize(image, ds_size_1), label))\n",
    "\n",
    "train_ds_1 = train_ds\n",
    "validation_ds_1 = validation_ds\n",
    "\n",
    "\n",
    "base_model_2 = keras.applications.ResNet50(weights='imagenet', include_top=False)\n",
    "n_classes = 3\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "\n",
    "# Rebuild top\n",
    "x = tf.keras.layers.GlobalAveragePooling2D(name=\"avg_pool\")(base_model_2.output)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "top_dropout_rate = 0.2\n",
    "x = tf.keras.layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
    "# x = tf.keras.layers.Flatten()(x)\n",
    "outputs = tf.keras.layers.Dense(3, activation=\"softmax\", name=\"pred\")(x) # match number of classes\n",
    "\n",
    "model_2 = keras.models.Model(inputs=base_model_2.input,\n",
    "                           outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 11:01:02.353890: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/341 [..............................] - ETA: 53:42 - loss: 1.1885 - accuracy: 0.3125"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 11:01:07.336341: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341/341 [==============================] - ETA: 0s - loss: 0.9200 - accuracy: 0.6267\n",
      "Epoch 1: saving model to ../checkpoints/training_ROUND3/cp.ckpt\n",
      "341/341 [==============================] - 148s 406ms/step - loss: 0.9200 - accuracy: 0.6267 - val_loss: 0.8385 - val_accuracy: 0.6728\n",
      "Epoch 2/3\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.8547 - accuracy: 0.6682\n",
      "Epoch 2: saving model to ../checkpoints/training_ROUND3/cp.ckpt\n",
      "341/341 [==============================] - 135s 397ms/step - loss: 0.8547 - accuracy: 0.6682 - val_loss: 0.8209 - val_accuracy: 0.6724\n",
      "Epoch 3/3\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.8428 - accuracy: 0.6719\n",
      "Epoch 3: saving model to ../checkpoints/training_ROUND3/cp.ckpt\n",
      "341/341 [==============================] - 136s 400ms/step - loss: 0.8428 - accuracy: 0.6719 - val_loss: 0.8336 - val_accuracy: 0.6728\n"
     ]
    }
   ],
   "source": [
    "# train up the top layer first\n",
    "\n",
    "for layer in base_model_2.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "recall = tf.keras.metrics.Recall()\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.01, decay=0.01)\n",
    "model_2.compile(loss=\"categorical_crossentropy\", optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model_2.fit(train_ds_1,\n",
    "                    validation_data=validation_ds_1,\n",
    "#                     class_weight=class_weights,\n",
    "                    epochs=3, callbacks=[callback,cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt = tf.keras.optimizers.Adam(0.1)\n",
    "# net = Net()\n",
    "# dataset = toy_dataset()\n",
    "# iterator = iter(dataset)\n",
    "# ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=optimizer, net=net, iterator=iterator)\n",
    "# manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=3)\n",
    "\n",
    "# train_and_checkpoint(net, manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 12:51:22.772587: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8101\n",
      "2022-04-26 12:51:27.915303: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341/341 [==============================] - ETA: 0s - loss: 1.0909 - accuracy: 0.5589\n",
      "Epoch 1: saving model to ../checkpoints/training_ROUND3/cp.ckpt\n",
      "341/341 [==============================] - 158s 429ms/step - loss: 1.0909 - accuracy: 0.5589 - val_loss: 8.1972 - val_accuracy: 0.6728\n",
      "Epoch 2/50\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.9076 - accuracy: 0.6552\n",
      "Epoch 2: saving model to ../checkpoints/training_ROUND3/cp.ckpt\n",
      "341/341 [==============================] - 138s 405ms/step - loss: 0.9076 - accuracy: 0.6552 - val_loss: 283.9296 - val_accuracy: 0.2384\n",
      "Epoch 3/50\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.9044 - accuracy: 0.6603\n",
      "Epoch 3: saving model to ../checkpoints/training_ROUND3/cp.ckpt\n",
      "341/341 [==============================] - 137s 401ms/step - loss: 0.9044 - accuracy: 0.6603 - val_loss: 0.8263 - val_accuracy: 0.6728\n",
      "Epoch 4/50\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.8883 - accuracy: 0.6643\n",
      "Epoch 4: saving model to ../checkpoints/training_ROUND3/cp.ckpt\n",
      "341/341 [==============================] - 137s 401ms/step - loss: 0.8883 - accuracy: 0.6643 - val_loss: 0.8261 - val_accuracy: 0.6728\n",
      "Epoch 5/50\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.8942 - accuracy: 0.6640\n",
      "Epoch 5: saving model to ../checkpoints/training_ROUND3/cp.ckpt\n",
      "341/341 [==============================] - 137s 401ms/step - loss: 0.8942 - accuracy: 0.6640 - val_loss: 1.0528 - val_accuracy: 0.6720\n",
      "Epoch 6/50\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.8786 - accuracy: 0.6651\n",
      "Epoch 6: saving model to ../checkpoints/training_ROUND3/cp.ckpt\n",
      "341/341 [==============================] - 137s 401ms/step - loss: 0.8786 - accuracy: 0.6651 - val_loss: 0.8154 - val_accuracy: 0.6860\n",
      "Epoch 7/50\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.8778 - accuracy: 0.6643\n",
      "Epoch 7: saving model to ../checkpoints/training_ROUND3/cp.ckpt\n",
      "341/341 [==============================] - 140s 412ms/step - loss: 0.8778 - accuracy: 0.6643 - val_loss: 0.8331 - val_accuracy: 0.6731\n",
      "Epoch 8/50\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.8787 - accuracy: 0.6650\n",
      "Epoch 8: saving model to ../checkpoints/training_ROUND3/cp.ckpt\n",
      "341/341 [==============================] - 137s 402ms/step - loss: 0.8787 - accuracy: 0.6650 - val_loss: 0.8618 - val_accuracy: 0.6728\n",
      "Epoch 9/50\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.8707 - accuracy: 0.6660\n",
      "Epoch 9: saving model to ../checkpoints/training_ROUND3/cp.ckpt\n",
      "341/341 [==============================] - 138s 404ms/step - loss: 0.8707 - accuracy: 0.6660 - val_loss: 0.8323 - val_accuracy: 0.6728\n",
      "Epoch 10/50\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.8733 - accuracy: 0.6651\n",
      "Epoch 10: saving model to ../checkpoints/training_ROUND3/cp.ckpt\n",
      "341/341 [==============================] - 137s 403ms/step - loss: 0.8733 - accuracy: 0.6651 - val_loss: 0.8256 - val_accuracy: 0.6728\n",
      "Epoch 11/50\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.8733 - accuracy: 0.6653\n",
      "Epoch 11: saving model to ../checkpoints/training_ROUND3/cp.ckpt\n",
      "341/341 [==============================] - 137s 403ms/step - loss: 0.8733 - accuracy: 0.6653 - val_loss: 0.8421 - val_accuracy: 0.6728\n",
      "Epoch 12/50\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.8673 - accuracy: 0.6647\n",
      "Epoch 12: saving model to ../checkpoints/training_ROUND3/cp.ckpt\n",
      "341/341 [==============================] - 137s 402ms/step - loss: 0.8673 - accuracy: 0.6647 - val_loss: 0.8299 - val_accuracy: 0.6728\n",
      "Epoch 13/50\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.8637 - accuracy: 0.6644\n",
      "Epoch 13: saving model to ../checkpoints/training_ROUND3/cp.ckpt\n",
      "341/341 [==============================] - 138s 404ms/step - loss: 0.8637 - accuracy: 0.6644 - val_loss: 1.3666 - val_accuracy: 0.6731\n",
      "Epoch 14/50\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.8637 - accuracy: 0.6670\n",
      "Epoch 14: saving model to ../checkpoints/training_ROUND3/cp.ckpt\n",
      "341/341 [==============================] - 138s 406ms/step - loss: 0.8637 - accuracy: 0.6670 - val_loss: 0.8402 - val_accuracy: 0.6728\n",
      "Epoch 15/50\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.8664 - accuracy: 0.6650\n",
      "Epoch 15: saving model to ../checkpoints/training_ROUND3/cp.ckpt\n",
      "341/341 [==============================] - 137s 401ms/step - loss: 0.8664 - accuracy: 0.6650 - val_loss: 0.8264 - val_accuracy: 0.6728\n",
      "Epoch 16/50\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.8694 - accuracy: 0.6664\n",
      "Epoch 16: saving model to ../checkpoints/training_ROUND3/cp.ckpt\n",
      "341/341 [==============================] - 137s 403ms/step - loss: 0.8694 - accuracy: 0.6664 - val_loss: 0.9007 - val_accuracy: 0.6728\n",
      "Epoch 17/50\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.8564 - accuracy: 0.6659"
     ]
    }
   ],
   "source": [
    "# train all the layers together for a bit with a much lower learning rate\n",
    "\n",
    "for layer in base_model_2.layers[-20:]:\n",
    "    if not isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "        layer.trainable = True\n",
    "\n",
    "recall = tf.keras.metrics.Recall()\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.0004, decay=0.001)\n",
    "model_2.compile(loss=\"categorical_crossentropy\", optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model_2.fit(train_ds_1,\n",
    "                    validation_data=validation_ds_1,\n",
    "#                     class_weight=class_weights,\n",
    "                    epochs=50, callbacks=[callback,cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train all the layers together for a bit with a much lower learning rate\n",
    "\n",
    "# for layer in base_model_2.layers[-20:]:\n",
    "#     if not isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "#         layer.trainable = True\n",
    "\n",
    "# recall = tf.keras.metrics.Recall()\n",
    "# optimizer = keras.optimizers.Adam(learning_rate=0.0004, decay=0.001)\n",
    "# model_2.compile(loss=\"categorical_crossentropy\", optimizer=optimizer,\n",
    "#               metrics=[\"accuracy\"])\n",
    "# history = model_2.fit(train_ds_1,\n",
    "#                     validation_data=validation_ds_1,\n",
    "# #                     class_weight=class_weights,\n",
    "#                     epochs=1, callbacks=[callback,cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "model_2.save('saved_models/model_ROUND3') # change this path to save a new version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if you need to use the checkpoint, use this code\n",
    "# # source: https://www.tensorflow.org/tutorials/keras/save_and_load#checkpoint_callback_options\n",
    "\n",
    "# latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "# latest\n",
    "\n",
    "# # Create a new model instance\n",
    "# model_2 = create_model()\n",
    "\n",
    "# # Load the previously saved weights\n",
    "# model_2.load_weights(latest)\n",
    "\n",
    "# # Re-evaluate the model\n",
    "# loss, acc = model_2.evaluate(validation_ds_1 verbose=2)\n",
    "# print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Do:\n",
    "\n",
    "Oversampling/Data Augmentation:\n",
    "\n",
    "1. start a new file with clear labels, resampling, augmented data\n",
    "2. Train the model the same way\n",
    "3. Save model and create confusion matrix in this file (or seperate file)\n",
    "\n",
    "Prediction weights\n",
    "1. When predicting classes, change wieghts until we get 100% for covid cases\n",
    "2. Change to proportional CM instead of just numeric?\n",
    "\n",
    "Recall and F-score as metric?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow 2.8.0/Keras Py3.9",
   "language": "python",
   "name": "tensorflow-2.8.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
