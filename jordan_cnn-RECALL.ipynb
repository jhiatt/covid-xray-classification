{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import sklearn\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import random as python_random\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "np.random.seed(42) # note that you must use the same seed to ensure consistentcy in your training/validation/testing\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "\n",
    "#### Questions:\n",
    "# How does tf (under this method) store labels? Can I access them?\n",
    "#    Look into how the resizing line is done\n",
    "# What happens if I don't pass the y value into imageDataGenerator().flow()?\n",
    "# is this enough work? (oversampling, data augmentation, adusting the prediction wieghts)\n",
    "# multiple expert -  3 different model (majority voting at the end to make predictions) - cost trade off for computing\n",
    "# - talk about costs (training time, different work, etc)\n",
    "# - accuracy vs tradeoffs (latency of making one prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md\t  jordan_cnn-manual-split.ipynb  resnet-jordan.ipynb\n",
      "checkpoints\t  jordan_cnn.ipynb\t\t resnet.ipynb\n",
      "dl_load.ipynb\t  matrix1.png\t\t\t resnet_v2.ipynb\n",
      "evaluation.ipynb  matrix2.png\t\t\t saved_models\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covid_img\n",
      "3611\n",
      "Viral_img\n",
      "1345\n",
      "Normal_img\n",
      "10193\n"
     ]
    }
   ],
   "source": [
    "data_path = '../dl_data/'\n",
    "class_names = os.listdir(data_path)\n",
    "class_dist = {}\n",
    "for c in class_names:\n",
    "    class_dist[c] = len(os.listdir(data_path + c))\n",
    "    print(c)\n",
    "    print(class_dist[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def pull_val(dir_path, val_path, portion):\n",
    "    # get a list of files to hold out for validation\n",
    "    files = os.listdir(dir_path)\n",
    "    length = len(files)\n",
    "    num_files = math.floor(length * portion)\n",
    "    val_files = np.random.choice(files, size=num_files, replace=False)\n",
    "\n",
    "    # move files\n",
    "    for f in val_files:\n",
    "        os.rename(dir_path + '/' + f, val_path + '/' + f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you need to, use this to make a new directory\n",
    "\n",
    "# os.mkdir('../HOLD_data')\n",
    "# os.mkdir('../test_data')\n",
    "# for c in class_names:\n",
    "#     os.mkdir('../HOLD_data/' + c)\n",
    "#     os.mkdir('../test_data/' + c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save out holdout and testing data\n",
    "\n",
    "portion = .10 # portion of data set aside for HOLDOUT\n",
    "    \n",
    "for c in class_names:\n",
    "    dir_path = '../dl_data/' + c\n",
    "    val_path = '../HOLD_data/' + c\n",
    "    pull_val(dir_path, val_path, portion)\n",
    "    \n",
    "##### Commented out because we will do validation split with the image gen function    \n",
    "# portion = .20 # portion of data set aside for TESTING\n",
    "    \n",
    "# for c in class_names:\n",
    "#     dir_path = '../dl_data/' + c\n",
    "#     val_path = '../test_data/' + c\n",
    "#     pull_val(dir_path, val_path, portion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to reset holdout\n",
    "\n",
    "# for c in class_names:\n",
    "#     val_files = os.listdir('../HOLD_data/' + c)\n",
    "#     for i in val_files:\n",
    "#         os.rename('../HOLD_data/' + c + '/' + i, '../dl_data/' + c + '/' + i)\n",
    "        \n",
    "# for c in class_names:\n",
    "#     val_files = os.listdir('../test_data/' + c)\n",
    "#     for i in val_files:\n",
    "#         os.rename('../test_data/' + c + '/' + i, '../dl_data/' + c + '/' + i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Train set-------------------\n",
      "Covid_img\n",
      "3250\n",
      "Viral_img\n",
      "1211\n",
      "Normal_img\n",
      "9174\n",
      "---Teset set-------------------\n",
      "Covid_img\n",
      "0\n",
      "Viral_img\n",
      "0\n",
      "Normal_img\n",
      "0\n",
      "---Holdout set-------------------\n",
      "Covid_img\n",
      "361\n",
      "Viral_img\n",
      "134\n",
      "Normal_img\n",
      "1019\n",
      "---Total-------------------\n",
      "Covid_img\n",
      "3611\n",
      "Viral_img\n",
      "1345\n",
      "Normal_img\n",
      "10193\n"
     ]
    }
   ],
   "source": [
    "print('---Train set-------------------')\n",
    "for c in class_names:\n",
    "    print(c)\n",
    "    print(len(os.listdir('../dl_data/'+c)))\n",
    "    \n",
    "print('---Teset set-------------------')\n",
    "for c in class_names:\n",
    "    print(c)\n",
    "    print(len(os.listdir('../test_data/'+c)))\n",
    "    \n",
    "print('---Holdout set-------------------')\n",
    "for c in class_names:\n",
    "    print(c)\n",
    "    print(len(os.listdir('../HOLD_data/'+c)))\n",
    "    \n",
    "print('---Total-------------------')\n",
    "for c in class_names:\n",
    "    print(c)\n",
    "    print(len(os.listdir('../dl_data/'+c)) + len(os.listdir('../HOLD_data/'+c)) + len(os.listdir('../test_data/'+c)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the data above isn't run, run this\n",
    "\n",
    "data_path = \"../dl_data/\"\n",
    "class_names = os.listdir(data_path)\n",
    "class_dist = {}\n",
    "for c in class_names:\n",
    "    class_dist[c] = len(os.listdir(data_path + c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Covid_img', 'Viral_img', 'Normal_img']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10912 images belonging to 3 classes.\n",
      "Found 2726 images belonging to 3 classes.\n",
      "Found 1514 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files \n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.preprocessing import image\n",
    "\n",
    "#### calculate class weights\n",
    "\n",
    "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "# The sum of the weights of all examples stays the same.\n",
    "total = sum(class_dist.values())\n",
    "weight_for_0 = (1 / class_dist[class_names[0]]) * (total / 2.0)\n",
    "weight_for_1 = (1 / class_dist[class_names[1]]) * (total / 2.0)\n",
    "weight_for_2 = (1 / class_dist[class_names[2]]) * (total / 2.0)\n",
    "\n",
    "class_weights = {0: weight_for_0, 1: weight_for_1, 2: weight_for_2}\n",
    "\n",
    "# directories\n",
    "data_dir = \"../dl_data\"\n",
    "# test_dir = \"../test_data\"\n",
    "HOLD_dir = \"../HOLD_data\"\n",
    "\n",
    "\n",
    "#### save out augmented data for visualization\n",
    "\n",
    "# ## first delete any existing files\n",
    "# aug_dir = '../augmented_data'\n",
    "# aug_files = os.listdir(aug_dir)\n",
    "# for f in aug_files:\n",
    "#     os.remove(aug_dir + '/' + f)\n",
    "\n",
    "    \n",
    "batch_size = 32;\n",
    "# IMPORTANT: Depends on what pre-trained model you choose, you will need to change these dimensions accordingly\n",
    "img_height = 224; \n",
    "img_width = 224;\n",
    "    \n",
    "\n",
    "# data augmentation (for training only)\n",
    "train_data_gen = ImageDataGenerator(rescale=1./255,\n",
    "                                    zoom_range= 0.3, \n",
    "                                    horizontal_flip= True, \n",
    "                                    shear_range= 0.2,\n",
    "                                    rotation_range = 30,\n",
    "                                    validation_split=0.2\n",
    "                                    \n",
    "                                    \n",
    "#                                     featurewise_center=False,\n",
    "#                                     samplewise_center=False,\n",
    "#                                     featurewise_std_normalization=False,\n",
    "#                                     samplewise_std_normalization=False,\n",
    "#                                     zca_whitening=False,\n",
    "#                                     zca_epsilon=1e-06,\n",
    "#                                     rotation_range=0,\n",
    "#                                     width_shift_range=0.0,\n",
    "#                                     height_shift_range=0.0,\n",
    "#                                     brightness_range=None,\n",
    "#                                     shear_range=0.0,\n",
    "#                                     zoom_range=0.0,\n",
    "#                                     channel_shift_range=0.0,\n",
    "#                                     fill_mode='nearest',\n",
    "#                                     cval=0.0,\n",
    "#                                     horizontal_flip=False,\n",
    "#                                     vertical_flip=False,\n",
    "#                                     rescale=None,\n",
    "#                                     preprocessing_function=None,\n",
    "#                                     data_format=None,\n",
    "#                                     validation_split=0.2,\n",
    "#                                     dtype=None\n",
    "                                    )\n",
    "\n",
    "\n",
    "train_ds = train_data_gen.flow_from_directory(\n",
    "    directory = data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    color_mode='rgb',\n",
    "    classes=None,\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "#     save_to_dir=aug_dir,\n",
    "#     save_prefix='aug',\n",
    "#     save_format='png',\n",
    "    follow_links=False,\n",
    "    subset='training',\n",
    "    interpolation='nearest'\n",
    ")\n",
    "\n",
    "validation_ds = train_data_gen.flow_from_directory(\n",
    "    directory=data_dir,  # same directory because we are splitting the data here\n",
    "    follow_links=False,\n",
    "    subset='validation',\n",
    "    interpolation='nearest',\n",
    "    target_size=(img_height, img_width), \n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "\n",
    "test_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "# holdout data\n",
    "HOLD_ds = test_data_gen.flow_from_directory(directory=HOLD_dir, \n",
    "                                         target_size=(img_height, img_width), \n",
    "                                         class_mode='categorical',\n",
    "                                         shuffle=True,\n",
    "                                         seed=42,\n",
    "                                         batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this is just a bug fix, hopefully I won't need to use it again.\n",
    "\n",
    "# fi = os.listdir(aug_dir + '/' + os.listdir(aug_dir)[0])\n",
    "# for f in fi:\n",
    "#     os.remove(aug_dir + '/' + os.listdir(aug_dir)[0] + '/' + f)\n",
    "\n",
    "# os.rmdir(aug_dir + '/' + os.listdir(aug_dir)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set checkpoint to resume training if it stops unexpectedly\n",
    "checkpoint_path = \"../checkpoints/training_2/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_size_1 = (224, 224)\n",
    "# train_ds_1 = train_ds.map(lambda image, label: (tf.image.resize(image, ds_size_1), label))\n",
    "# validation_ds_1 = validation_ds.map(lambda image, label: (tf.image.resize(image, ds_size_1), label))\n",
    "\n",
    "train_ds_1 = train_ds\n",
    "validation_ds_1 = validation_ds\n",
    "\n",
    "\n",
    "base_model_2 = keras.applications.ResNet50(weights='imagenet', include_top=False)\n",
    "n_classes = 3\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "\n",
    "# Rebuild top\n",
    "x = tf.keras.layers.GlobalAveragePooling2D(name=\"avg_pool\")(base_model_2.output)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "top_dropout_rate = 0.2\n",
    "x = tf.keras.layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
    "# x = tf.keras.layers.Flatten()(x)\n",
    "outputs = tf.keras.layers.Dense(3, activation=\"softmax\", name=\"pred\")(x) # match number of classes\n",
    "\n",
    "model_2 = keras.models.Model(inputs=base_model_2.input,\n",
    "                           outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.6408 - accuracy: 0.7106\n",
      "Epoch 1: saving model to ../checkpoints/training_2/cp.ckpt\n",
      "341/341 [==============================] - 180s 519ms/step - loss: 0.6408 - accuracy: 0.7106 - val_loss: 0.8320 - val_accuracy: 0.6728\n",
      "Epoch 2/20\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.5639 - accuracy: 0.7407\n",
      "Epoch 2: saving model to ../checkpoints/training_2/cp.ckpt\n",
      "341/341 [==============================] - 176s 517ms/step - loss: 0.5639 - accuracy: 0.7407 - val_loss: 0.5668 - val_accuracy: 0.7432\n",
      "Epoch 3/20\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.5555 - accuracy: 0.7489\n",
      "Epoch 3: saving model to ../checkpoints/training_2/cp.ckpt\n",
      "341/341 [==============================] - 174s 510ms/step - loss: 0.5555 - accuracy: 0.7489 - val_loss: 0.5584 - val_accuracy: 0.7612\n",
      "Epoch 4/20\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.5477 - accuracy: 0.7565\n",
      "Epoch 4: saving model to ../checkpoints/training_2/cp.ckpt\n",
      "341/341 [==============================] - 174s 509ms/step - loss: 0.5477 - accuracy: 0.7565 - val_loss: 0.5395 - val_accuracy: 0.7748\n",
      "Epoch 5/20\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.5459 - accuracy: 0.7594\n",
      "Epoch 5: saving model to ../checkpoints/training_2/cp.ckpt\n",
      "341/341 [==============================] - 174s 511ms/step - loss: 0.5459 - accuracy: 0.7594 - val_loss: 0.5453 - val_accuracy: 0.7689\n",
      "Epoch 6/20\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.5301 - accuracy: 0.7667\n",
      "Epoch 6: saving model to ../checkpoints/training_2/cp.ckpt\n",
      "341/341 [==============================] - 174s 509ms/step - loss: 0.5301 - accuracy: 0.7667 - val_loss: 0.5318 - val_accuracy: 0.7718\n",
      "Epoch 7/20\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.5432 - accuracy: 0.7569\n",
      "Epoch 7: saving model to ../checkpoints/training_2/cp.ckpt\n",
      "341/341 [==============================] - 175s 512ms/step - loss: 0.5432 - accuracy: 0.7569 - val_loss: 0.5396 - val_accuracy: 0.7722\n",
      "Epoch 8/20\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.5381 - accuracy: 0.7565\n",
      "Epoch 8: saving model to ../checkpoints/training_2/cp.ckpt\n",
      "341/341 [==============================] - 174s 510ms/step - loss: 0.5381 - accuracy: 0.7565 - val_loss: 0.5420 - val_accuracy: 0.7726\n",
      "Epoch 9/20\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.5380 - accuracy: 0.7548\n",
      "Epoch 9: saving model to ../checkpoints/training_2/cp.ckpt\n",
      "341/341 [==============================] - 176s 516ms/step - loss: 0.5380 - accuracy: 0.7548 - val_loss: 0.5291 - val_accuracy: 0.7766\n",
      "Epoch 10/20\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.5358 - accuracy: 0.7572\n",
      "Epoch 10: saving model to ../checkpoints/training_2/cp.ckpt\n",
      "341/341 [==============================] - 175s 514ms/step - loss: 0.5358 - accuracy: 0.7572 - val_loss: 0.5238 - val_accuracy: 0.7806\n",
      "Epoch 11/20\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.5288 - accuracy: 0.7655\n",
      "Epoch 11: saving model to ../checkpoints/training_2/cp.ckpt\n",
      "341/341 [==============================] - 175s 514ms/step - loss: 0.5288 - accuracy: 0.7655 - val_loss: 0.5390 - val_accuracy: 0.7726\n",
      "Epoch 12/20\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.5286 - accuracy: 0.7631\n",
      "Epoch 12: saving model to ../checkpoints/training_2/cp.ckpt\n",
      "341/341 [==============================] - 176s 516ms/step - loss: 0.5286 - accuracy: 0.7631 - val_loss: 0.5250 - val_accuracy: 0.7803\n",
      "Epoch 13/20\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.5314 - accuracy: 0.7607\n",
      "Epoch 13: saving model to ../checkpoints/training_2/cp.ckpt\n",
      "341/341 [==============================] - 175s 514ms/step - loss: 0.5314 - accuracy: 0.7607 - val_loss: 0.5217 - val_accuracy: 0.7902\n",
      "Epoch 14/20\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.5355 - accuracy: 0.7608\n",
      "Epoch 14: saving model to ../checkpoints/training_2/cp.ckpt\n",
      "341/341 [==============================] - 175s 514ms/step - loss: 0.5355 - accuracy: 0.7608 - val_loss: 0.5228 - val_accuracy: 0.7755\n",
      "Epoch 15/20\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.5347 - accuracy: 0.7590\n",
      "Epoch 15: saving model to ../checkpoints/training_2/cp.ckpt\n",
      "341/341 [==============================] - 175s 515ms/step - loss: 0.5347 - accuracy: 0.7590 - val_loss: 0.5252 - val_accuracy: 0.7850\n",
      "Epoch 16/20\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.5347 - accuracy: 0.7601\n",
      "Epoch 16: saving model to ../checkpoints/training_2/cp.ckpt\n",
      "341/341 [==============================] - 177s 520ms/step - loss: 0.5347 - accuracy: 0.7601 - val_loss: 0.5302 - val_accuracy: 0.7828\n",
      "Epoch 17/20\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.5262 - accuracy: 0.7626\n",
      "Epoch 17: saving model to ../checkpoints/training_2/cp.ckpt\n",
      "341/341 [==============================] - 174s 511ms/step - loss: 0.5262 - accuracy: 0.7626 - val_loss: 0.5167 - val_accuracy: 0.7825\n",
      "Epoch 18/20\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.5218 - accuracy: 0.7669\n",
      "Epoch 18: saving model to ../checkpoints/training_2/cp.ckpt\n",
      "341/341 [==============================] - 174s 511ms/step - loss: 0.5218 - accuracy: 0.7669 - val_loss: 0.5222 - val_accuracy: 0.7810\n",
      "Epoch 19/20\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.5298 - accuracy: 0.7652\n",
      "Epoch 19: saving model to ../checkpoints/training_2/cp.ckpt\n",
      "341/341 [==============================] - 174s 511ms/step - loss: 0.5298 - accuracy: 0.7652 - val_loss: 0.5345 - val_accuracy: 0.7773\n",
      "Epoch 20/20\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.5278 - accuracy: 0.7600\n",
      "Epoch 20: saving model to ../checkpoints/training_2/cp.ckpt\n",
      "341/341 [==============================] - 175s 513ms/step - loss: 0.5278 - accuracy: 0.7600 - val_loss: 0.5170 - val_accuracy: 0.7770\n"
     ]
    }
   ],
   "source": [
    "# train up the top layer first\n",
    "\n",
    "for layer in base_model_2.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "recall = tf.keras.metrics.Recall\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.01, decay=0.01)\n",
    "model_2.compile(loss=\"categorical_crossentropy\", optimizer=optimizer,\n",
    "              metrics=[recall])\n",
    "history = model_2.fit(train_ds_1,\n",
    "                    validation_data=validation_ds_1,\n",
    "#                     class_weight=class_weights,\n",
    "                    epochs=20, callbacks=[callback,cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt = tf.keras.optimizers.Adam(0.1)\n",
    "# net = Net()\n",
    "# dataset = toy_dataset()\n",
    "# iterator = iter(dataset)\n",
    "# ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=optimizer, net=net, iterator=iterator)\n",
    "# manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=3)\n",
    "\n",
    "# train_and_checkpoint(net, manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.7362 - accuracy: 0.6940\n",
      "Epoch 1: saving model to ../checkpoints/training_2/cp.ckpt\n",
      "341/341 [==============================] - 179s 515ms/step - loss: 0.7362 - accuracy: 0.6940 - val_loss: 13.9143 - val_accuracy: 0.2384\n",
      "Epoch 2/50\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.6195 - accuracy: 0.7337\n",
      "Epoch 2: saving model to ../checkpoints/training_2/cp.ckpt\n",
      "341/341 [==============================] - 174s 511ms/step - loss: 0.6195 - accuracy: 0.7337 - val_loss: 94.1256 - val_accuracy: 0.0888\n",
      "Epoch 3/50\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.5934 - accuracy: 0.7501\n",
      "Epoch 3: saving model to ../checkpoints/training_2/cp.ckpt\n",
      "341/341 [==============================] - 175s 513ms/step - loss: 0.5934 - accuracy: 0.7501 - val_loss: 25.7096 - val_accuracy: 0.2384\n",
      "Epoch 4/50\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.5596 - accuracy: 0.7636\n",
      "Epoch 4: saving model to ../checkpoints/training_2/cp.ckpt\n",
      "341/341 [==============================] - 176s 515ms/step - loss: 0.5596 - accuracy: 0.7636 - val_loss: 13.7972 - val_accuracy: 0.6728\n",
      "Epoch 5/50\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.5412 - accuracy: 0.7725\n",
      "Epoch 5: saving model to ../checkpoints/training_2/cp.ckpt\n",
      "341/341 [==============================] - 175s 513ms/step - loss: 0.5412 - accuracy: 0.7725 - val_loss: 9.7936 - val_accuracy: 0.6728\n",
      "Epoch 6/50\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.5216 - accuracy: 0.7793\n",
      "Epoch 6: saving model to ../checkpoints/training_2/cp.ckpt\n",
      "341/341 [==============================] - 175s 513ms/step - loss: 0.5216 - accuracy: 0.7793 - val_loss: 10.5094 - val_accuracy: 0.6728\n",
      "Epoch 7/50\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.4991 - accuracy: 0.7867\n",
      "Epoch 7: saving model to ../checkpoints/training_2/cp.ckpt\n",
      "341/341 [==============================] - 175s 514ms/step - loss: 0.4991 - accuracy: 0.7867 - val_loss: 3.1355 - val_accuracy: 0.7425\n",
      "Epoch 8/50\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.4965 - accuracy: 0.7909\n",
      "Epoch 8: saving model to ../checkpoints/training_2/cp.ckpt\n",
      "341/341 [==============================] - 175s 513ms/step - loss: 0.4965 - accuracy: 0.7909 - val_loss: 131.3436 - val_accuracy: 0.0888\n",
      "Epoch 9/50\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.4818 - accuracy: 0.7971\n",
      "Epoch 9: saving model to ../checkpoints/training_2/cp.ckpt\n",
      "341/341 [==============================] - 175s 512ms/step - loss: 0.4818 - accuracy: 0.7971 - val_loss: 10.1449 - val_accuracy: 0.2392\n",
      "Epoch 10/50\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.4786 - accuracy: 0.8035\n",
      "Epoch 10: saving model to ../checkpoints/training_2/cp.ckpt\n",
      "341/341 [==============================] - 174s 510ms/step - loss: 0.4786 - accuracy: 0.8035 - val_loss: 28.6757 - val_accuracy: 0.1012\n",
      "Epoch 11/50\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.4604 - accuracy: 0.8065\n",
      "Epoch 11: saving model to ../checkpoints/training_2/cp.ckpt\n",
      "341/341 [==============================] - 175s 514ms/step - loss: 0.4604 - accuracy: 0.8065 - val_loss: 32.2328 - val_accuracy: 0.2384\n",
      "Epoch 12/50\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.4584 - accuracy: 0.8076\n",
      "Epoch 12: saving model to ../checkpoints/training_2/cp.ckpt\n",
      "341/341 [==============================] - 176s 516ms/step - loss: 0.4584 - accuracy: 0.8076 - val_loss: 5.1630 - val_accuracy: 0.7175\n",
      "Epoch 13/50\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.4464 - accuracy: 0.8152\n",
      "Epoch 13: saving model to ../checkpoints/training_2/cp.ckpt\n",
      "341/341 [==============================] - 175s 512ms/step - loss: 0.4464 - accuracy: 0.8152 - val_loss: 9.5217 - val_accuracy: 0.6728\n",
      "Epoch 14/50\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.4390 - accuracy: 0.8169\n",
      "Epoch 14: saving model to ../checkpoints/training_2/cp.ckpt\n",
      "341/341 [==============================] - 174s 509ms/step - loss: 0.4390 - accuracy: 0.8169 - val_loss: 69.7493 - val_accuracy: 0.0888\n",
      "Epoch 15/50\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.4345 - accuracy: 0.8176\n",
      "Epoch 15: saving model to ../checkpoints/training_2/cp.ckpt\n",
      "341/341 [==============================] - 174s 510ms/step - loss: 0.4345 - accuracy: 0.8176 - val_loss: 6.6940 - val_accuracy: 0.6731\n",
      "Epoch 16/50\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.4270 - accuracy: 0.8241"
     ]
    }
   ],
   "source": [
    "# train all the layers together for a bit with a much lower learning rate\n",
    "\n",
    "for layer in base_model_2.layers[-20:]:\n",
    "    if not isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "        layer.trainable = True\n",
    "\n",
    "recall = tf.keras.metrics.Recall\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.0004, decay=0.001)\n",
    "model_2.compile(loss=\"categorical_crossentropy\", optimizer=optimizer,\n",
    "              metrics=[recall])\n",
    "history = model_2.fit(train_ds_1,\n",
    "                    validation_data=validation_ds_1,\n",
    "#                     class_weight=class_weights,\n",
    "                    epochs=50, callbacks=[callback,cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# save the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel_2\u001b[49m\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaved_models/model_RECALL\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_2' is not defined"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "model_2.save('saved_models/model_RECALL') # change this path to save a new version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if you need to use the checkpoint, use this code\n",
    "# # source: https://www.tensorflow.org/tutorials/keras/save_and_load#checkpoint_callback_options\n",
    "\n",
    "# latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "# latest\n",
    "\n",
    "# # Create a new model instance\n",
    "# model_2 = create_model()\n",
    "\n",
    "# # Load the previously saved weights\n",
    "# model_2.load_weights(latest)\n",
    "\n",
    "# # Re-evaluate the model\n",
    "# loss, acc = model_2.evaluate(validation_ds_1 verbose=2)\n",
    "# print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Do:\n",
    "\n",
    "Oversampling/Data Augmentation:\n",
    "\n",
    "1. start a new file with clear labels, resampling, augmented data\n",
    "2. Train the model the same way\n",
    "3. Save model and create confusion matrix in this file (or seperate file)\n",
    "\n",
    "Prediction weights\n",
    "1. When predicting classes, change wieghts until we get 100% for covid cases\n",
    "2. Change to proportional CM instead of just numeric?\n",
    "\n",
    "Recall and F-score as metric?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow 2.8.0/Keras Py3.9",
   "language": "python",
   "name": "tensorflow-2.8.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
