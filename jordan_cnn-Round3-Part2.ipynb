{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import sklearn\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import random as python_random\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "np.random.seed(42) # note that you must use the same seed to ensure consistentcy in your training/validation/testing\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESNET Round 3, Part 2\n",
    "This model has already been trained for x-ray data, now we retrain on data that has been upsapmpled (for small classes) and downsampled (for large classes) to balance classes.\n",
    "\n",
    "I've decided to get 5,000 records of each"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upsample the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Covid_img': 3250, 'Viral_img': 1211, 'Normal_img': 9174}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if the data above isn't run, run this\n",
    "\n",
    "data_path = \"../dl_data/\"\n",
    "class_names = os.listdir(data_path)\n",
    "class_dist = {} # get the originial distribution of each class\n",
    "f_names = {} # get list of file paths per class\n",
    "for c in class_names:\n",
    "    class_dist[c] = len(os.listdir(data_path + c))\n",
    "    f_names[c] = os.listdir(data_path + c)\n",
    "class_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['COVID-2402.png',\n",
       " 'COVID-1270.png',\n",
       " 'COVID-3070.png',\n",
       " 'COVID-2019.png',\n",
       " 'COVID-2463.png',\n",
       " 'COVID-396.png',\n",
       " 'COVID-3605.png',\n",
       " 'COVID-256.png',\n",
       " 'COVID-1215.png',\n",
       " 'COVID-1649.png']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_names['Covid_img'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['COVID-2580.png', 'COVID-3026.png', 'COVID-118.png',\n",
       "       'COVID-1079.png', 'COVID-1944.png', 'COVID-3587.png',\n",
       "       'COVID-2915.png', 'COVID-3351.png', 'COVID-978.png',\n",
       "       'COVID-986.png', 'COVID-3111.png', 'COVID-603.png',\n",
       "       'COVID-359.png', 'COVID-2141.png', 'COVID-330.png',\n",
       "       'COVID-1380.png', 'COVID-1447.png', 'COVID-3129.png',\n",
       "       'COVID-2817.png', 'COVID-2560.png'], dtype='<U18')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(f_names['Covid_img'], size=20, replace=True, p=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Covid_img': array(['COVID-2382.png', 'COVID-3052.png', 'COVID-2420.png', ...,\n",
       "        'COVID-1967.png', 'COVID-3399.png', 'COVID-2705.png'], dtype='<U18'),\n",
       " 'Viral_img': array(['Viral Pneumonia-763.png', 'Viral Pneumonia-380.png',\n",
       "        'Viral Pneumonia-42.png', ..., 'Viral Pneumonia-417.png',\n",
       "        'Viral Pneumonia-548.png', 'Viral Pneumonia-265.png'], dtype='<U24'),\n",
       " 'Normal_img': array(['Normal-837.png', 'Normal-8169.png', 'Normal-5229.png', ...,\n",
       "        'Normal-1890.png', 'Normal-5930.png', 'Normal-9437.png'],\n",
       "       dtype='<U18')}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get samples\n",
    "sample_paths = {}\n",
    "for c in f_names:\n",
    "    sample_paths[c] = np.random.choice(f_names[c], size=5000, replace=True, p=None)\n",
    "sample_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "5000\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "for c in sample_paths:\n",
    "    print(len(sample_paths[c]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you need to, use this to make a new directory\n",
    "\n",
    "os.mkdir('../sample_data')\n",
    "for c in class_names:\n",
    "    os.mkdir('../sample_data/' + c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../dl_data/Covid_img\n",
      "../dl_data/Viral_img\n",
      "../dl_data/Normal_img\n"
     ]
    }
   ],
   "source": [
    "# copy sampled files over\n",
    "new_path = '../sample_data/'\n",
    "\n",
    "for c in sample_paths:\n",
    "    print(data_path + c)\n",
    "    for i, p in enumerate(sample_paths[c]):\n",
    "        shutil.copyfile(data_path + c + '/' + p, new_path + c + '/' + str(i) + '_' + p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Covid_img': 5000, 'Viral_img': 5000, 'Normal_img': 5000}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that the new data has arrived\n",
    "new_class_dist = {} # get the originial distribution of each class\n",
    "for c in class_names:\n",
    "    new_class_dist[c] = len(os.listdir(new_path + c))\n",
    "new_class_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if you need to start over\n",
    "# for c in class_names:\n",
    "#     all_files = os.listdir(new_path + c)\n",
    "#     for f in all_files:\n",
    "#         os.remove(new_path + c+ '/' + f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15000 files belonging to 3 classes.\n",
      "Using 12000 files for training.\n",
      "Found 15000 files belonging to 3 classes.\n",
      "Using 3000 files for validation.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files \n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.preprocessing import image\n",
    "\n",
    "\n",
    "\n",
    "# directories\n",
    "data_dir = \"../sample_data/\"\n",
    "\n",
    "#### save out augmented data for visualization\n",
    "\n",
    "# ## first delete any existing files\n",
    "# aug_dir = '../augmented_data'\n",
    "# aug_files = os.listdir(aug_dir)\n",
    "# for f in aug_files:\n",
    "#     os.remove(aug_dir + '/' + f)\n",
    "\n",
    "    \n",
    "batch_size = 32;\n",
    "# IMPORTANT: Depends on what pre-trained model you choose, you will need to change these dimensions accordingly\n",
    "img_height = 224; \n",
    "img_width = 224;\n",
    "    \n",
    "    \n",
    "# Test Dataset\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split = 0.2,\n",
    "    subset = \"training\",\n",
    "    seed = 42,\n",
    "    image_size= (img_height, img_width),\n",
    "    batch_size = batch_size\n",
    ")\n",
    "\n",
    "# Test Dataset\n",
    "validation_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split = 0.2,\n",
    "    subset = \"validation\",\n",
    "    seed = 42,\n",
    "    image_size= (img_height, img_width),\n",
    "    batch_size = batch_size\n",
    ")\n",
    "\n",
    "# # data augmentation (for training only)\n",
    "# train_data_gen = ImageDataGenerator(rescale=1./255,\n",
    "#                                     zoom_range= 0.3, \n",
    "#                                     horizontal_flip= True, \n",
    "#                                     shear_range= 0.2,\n",
    "#                                     rotation_range = 30,\n",
    "#                                     validation_split=0.2\n",
    "\n",
    "#                                     )\n",
    "\n",
    "\n",
    "\n",
    "# train_ds = train_data_gen.flow_from_directory(\n",
    "#     directory = data_dir,\n",
    "#     target_size=(img_height, img_width),\n",
    "#     color_mode='rgb',\n",
    "#     classes=None,\n",
    "#     class_mode='categorical',\n",
    "#     batch_size=batch_size,\n",
    "#     shuffle=False,\n",
    "#     seed=42,\n",
    "# #     save_to_dir=aug_dir,\n",
    "# #     save_prefix='aug',\n",
    "# #     save_format='png',\n",
    "#     follow_links=False,\n",
    "#     subset='training',\n",
    "#     interpolation='nearest'\n",
    "# )\n",
    "\n",
    "# validation_ds = train_data_gen.flow_from_directory(\n",
    "#     directory=data_dir,  # same directory because we are splitting the data here\n",
    "#     follow_links=False,\n",
    "#     subset='validation',\n",
    "#     interpolation='nearest',\n",
    "#     target_size=(img_height, img_width), \n",
    "#     class_mode='categorical',\n",
    "#     shuffle=False,\n",
    "#     seed=42,\n",
    "#     batch_size=batch_size\n",
    "# )\n",
    "\n",
    "# class_ind = (train_ds.class_indices)\n",
    "\n",
    "# test_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "# # holdout data\n",
    "# HOLD_ds = test_data_gen.flow_from_directory(directory=HOLD_dir, \n",
    "#                                          target_size=(img_height, img_width), \n",
    "#                                          class_mode='categorical',\n",
    "#                                          shuffle=False,\n",
    "#                                          seed=42,\n",
    "#                                          batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_ind\n",
    "\n",
    "# scikitlearn funciton for recall/precision etc. scikitlearn.metrics\n",
    "#train on accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this is just a bug fix, hopefully I won't need to use it again.\n",
    "\n",
    "# fi = os.listdir(aug_dir + '/' + os.listdir(aug_dir)[0])\n",
    "# for f in fi:\n",
    "#     os.remove(aug_dir + '/' + os.listdir(aug_dir)[0] + '/' + f)\n",
    "\n",
    "# os.rmdir(aug_dir + '/' + os.listdir(aug_dir)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set checkpoint to resume training if it stops unexpectedly\n",
    "checkpoint_path = \"../checkpoints/training_ROUND3_part2/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Inputs to a layer should be tensors. Got: <keras.layers.core.dropout.Dropout object at 0x7f3852082a60>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [58]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m x \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDropout(top_dropout_rate, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_dropout\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;66;03m#(x)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# x = tf.keras.layers.Flatten()(x)\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msoftmax\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpred\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# match number of classes\u001b[39;00m\n\u001b[1;32m     23\u001b[0m model_2 \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39mbase_model_2\u001b[38;5;241m.\u001b[39minput,\n\u001b[1;32m     24\u001b[0m                            outputs\u001b[38;5;241m=\u001b[39moutputs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/keras/engine/input_spec.py:197\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m inputs:\n\u001b[1;32m    192\u001b[0m   \u001b[38;5;66;03m# Having a shape/dtype is the only commonality of the various tensor-like\u001b[39;00m\n\u001b[1;32m    193\u001b[0m   \u001b[38;5;66;03m# objects that may be passed. The most common kind of invalid type we are\u001b[39;00m\n\u001b[1;32m    194\u001b[0m   \u001b[38;5;66;03m# guarding for is a Layer instance (Functional API), which does not\u001b[39;00m\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;66;03m# have a `shape` attribute.\u001b[39;00m\n\u001b[1;32m    196\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 197\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInputs to a layer should be tensors. Got: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inputs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(input_spec):\n\u001b[1;32m    200\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLayer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m expects \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(input_spec)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m input(s),\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    201\u001b[0m                    \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m but it received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(inputs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m input tensors. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    202\u001b[0m                    \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInputs received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minputs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Inputs to a layer should be tensors. Got: <keras.layers.core.dropout.Dropout object at 0x7f3852082a60>"
     ]
    }
   ],
   "source": [
    "# ds_size_1 = (224, 224)\n",
    "# # train_ds_1 = train_ds.map(lambda image, label: (tf.image.resize(image, ds_size_1), label))\n",
    "# # validation_ds_1 = validation_ds.map(lambda image, label: (tf.image.resize(image, ds_size_1), label))\n",
    "\n",
    "# train_ds_1 = train_ds\n",
    "# validation_ds_1 = validation_ds\n",
    "\n",
    "\n",
    "# base_model_2 = tf.keras.models.load_model('./saved_models/model_ROUND3')\n",
    "# n_classes = 3\n",
    "\n",
    "# callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "\n",
    "# # Rebuild top\n",
    "# # x = tf.keras.layers.GlobalAveragePooling2D(name=\"avg_pool\")(base_model_2.output)\n",
    "# # x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "# top_dropout_rate = 0.2\n",
    "# x = tf.keras.layers.Dropout(top_dropout_rate, name=\"top_dropout\")#(x)\n",
    "# # x = tf.keras.layers.Flatten()(x)\n",
    "# outputs = tf.keras.layers.Dense(3, activation=\"softmax\", name=\"pred\")(x) # match number of classes\n",
    "\n",
    "# model_2 = keras.models.Model(inputs=base_model_2.input,\n",
    "#                            outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "375/375 [==============================] - ETA: 0s - loss: 1.1069 - accuracy: 0.5993\n",
      "Epoch 1: saving model to ../checkpoints/training_ROUND3_part2/cp.ckpt\n",
      "375/375 [==============================] - 31s 73ms/step - loss: 1.1069 - accuracy: 0.5993 - val_loss: 0.9827 - val_accuracy: 0.7173\n",
      "Epoch 2/20\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.5386 - accuracy: 0.7695\n",
      "Epoch 2: saving model to ../checkpoints/training_ROUND3_part2/cp.ckpt\n",
      "375/375 [==============================] - 27s 71ms/step - loss: 0.5386 - accuracy: 0.7695 - val_loss: 0.5366 - val_accuracy: 0.7853\n",
      "Epoch 3/20\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.3693 - accuracy: 0.8458\n",
      "Epoch 3: saving model to ../checkpoints/training_ROUND3_part2/cp.ckpt\n",
      "375/375 [==============================] - 27s 71ms/step - loss: 0.3693 - accuracy: 0.8458 - val_loss: 0.3855 - val_accuracy: 0.8250\n",
      "Epoch 4/20\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.2518 - accuracy: 0.9018\n",
      "Epoch 4: saving model to ../checkpoints/training_ROUND3_part2/cp.ckpt\n",
      "375/375 [==============================] - 27s 71ms/step - loss: 0.2518 - accuracy: 0.9018 - val_loss: 0.2168 - val_accuracy: 0.9123\n",
      "Epoch 5/20\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.1823 - accuracy: 0.9315\n",
      "Epoch 5: saving model to ../checkpoints/training_ROUND3_part2/cp.ckpt\n",
      "375/375 [==============================] - 27s 71ms/step - loss: 0.1823 - accuracy: 0.9315 - val_loss: 0.1848 - val_accuracy: 0.9277\n",
      "Epoch 6/20\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.1355 - accuracy: 0.9490\n",
      "Epoch 6: saving model to ../checkpoints/training_ROUND3_part2/cp.ckpt\n",
      "375/375 [==============================] - 27s 71ms/step - loss: 0.1355 - accuracy: 0.9490 - val_loss: 0.1747 - val_accuracy: 0.9393\n",
      "Epoch 7/20\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.1005 - accuracy: 0.9659\n",
      "Epoch 7: saving model to ../checkpoints/training_ROUND3_part2/cp.ckpt\n",
      "375/375 [==============================] - 27s 72ms/step - loss: 0.1005 - accuracy: 0.9659 - val_loss: 0.1573 - val_accuracy: 0.9373\n",
      "Epoch 8/20\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0752 - accuracy: 0.9756\n",
      "Epoch 8: saving model to ../checkpoints/training_ROUND3_part2/cp.ckpt\n",
      "375/375 [==============================] - 27s 72ms/step - loss: 0.0752 - accuracy: 0.9756 - val_loss: 0.1689 - val_accuracy: 0.9387\n",
      "Epoch 9/20\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0568 - accuracy: 0.9813\n",
      "Epoch 9: saving model to ../checkpoints/training_ROUND3_part2/cp.ckpt\n",
      "375/375 [==============================] - 27s 71ms/step - loss: 0.0568 - accuracy: 0.9813 - val_loss: 0.0722 - val_accuracy: 0.9753\n",
      "Epoch 10/20\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0544 - accuracy: 0.9825\n",
      "Epoch 10: saving model to ../checkpoints/training_ROUND3_part2/cp.ckpt\n",
      "375/375 [==============================] - 27s 71ms/step - loss: 0.0544 - accuracy: 0.9825 - val_loss: 0.0565 - val_accuracy: 0.9837\n",
      "Epoch 11/20\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0316 - accuracy: 0.9904\n",
      "Epoch 11: saving model to ../checkpoints/training_ROUND3_part2/cp.ckpt\n",
      "375/375 [==============================] - 27s 71ms/step - loss: 0.0316 - accuracy: 0.9904 - val_loss: 0.0589 - val_accuracy: 0.9803\n",
      "Epoch 12/20\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0229 - accuracy: 0.9936\n",
      "Epoch 12: saving model to ../checkpoints/training_ROUND3_part2/cp.ckpt\n",
      "375/375 [==============================] - 27s 71ms/step - loss: 0.0229 - accuracy: 0.9936 - val_loss: 0.0553 - val_accuracy: 0.9823\n",
      "Epoch 13/20\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0203 - accuracy: 0.9942\n",
      "Epoch 13: saving model to ../checkpoints/training_ROUND3_part2/cp.ckpt\n",
      "375/375 [==============================] - 27s 71ms/step - loss: 0.0203 - accuracy: 0.9942 - val_loss: 0.0833 - val_accuracy: 0.9743\n",
      "Epoch 14/20\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0209 - accuracy: 0.9937\n",
      "Epoch 14: saving model to ../checkpoints/training_ROUND3_part2/cp.ckpt\n",
      "375/375 [==============================] - 27s 73ms/step - loss: 0.0209 - accuracy: 0.9937 - val_loss: 0.0733 - val_accuracy: 0.9783\n",
      "Epoch 15/20\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 0.9968\n",
      "Epoch 15: saving model to ../checkpoints/training_ROUND3_part2/cp.ckpt\n",
      "375/375 [==============================] - 27s 71ms/step - loss: 0.0121 - accuracy: 0.9968 - val_loss: 0.0514 - val_accuracy: 0.9857\n",
      "Epoch 16/20\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0128 - accuracy: 0.9959\n",
      "Epoch 16: saving model to ../checkpoints/training_ROUND3_part2/cp.ckpt\n",
      "375/375 [==============================] - 27s 71ms/step - loss: 0.0128 - accuracy: 0.9959 - val_loss: 0.0678 - val_accuracy: 0.9793\n",
      "Epoch 17/20\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 0.9937\n",
      "Epoch 17: saving model to ../checkpoints/training_ROUND3_part2/cp.ckpt\n",
      "375/375 [==============================] - 28s 76ms/step - loss: 0.0174 - accuracy: 0.9937 - val_loss: 0.0665 - val_accuracy: 0.9800\n",
      "Epoch 18/20\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9973\n",
      "Epoch 18: saving model to ../checkpoints/training_ROUND3_part2/cp.ckpt\n",
      "375/375 [==============================] - 27s 72ms/step - loss: 0.0086 - accuracy: 0.9973 - val_loss: 0.0538 - val_accuracy: 0.9843\n",
      "Epoch 19/20\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 0.9977\n",
      "Epoch 19: saving model to ../checkpoints/training_ROUND3_part2/cp.ckpt\n",
      "375/375 [==============================] - 27s 71ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.0587 - val_accuracy: 0.9813\n",
      "Epoch 20/20\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 0.9965\n",
      "Epoch 20: saving model to ../checkpoints/training_ROUND3_part2/cp.ckpt\n",
      "375/375 [==============================] - 27s 72ms/step - loss: 0.0106 - accuracy: 0.9965 - val_loss: 0.0511 - val_accuracy: 0.9860\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'loaded_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [62]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m model_2\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[1;32m     13\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     14\u001b[0m history \u001b[38;5;241m=\u001b[39m model_2\u001b[38;5;241m.\u001b[39mfit(train_ds_1,\n\u001b[1;32m     15\u001b[0m                     validation_data\u001b[38;5;241m=\u001b[39mvalidation_ds_1,\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#                     class_weight=class_weights,\u001b[39;00m\n\u001b[1;32m     17\u001b[0m                     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, callbacks\u001b[38;5;241m=\u001b[39m[callback,cp_callback])\n\u001b[0;32m---> 19\u001b[0m \u001b[43mloaded_model\u001b[49m\u001b[38;5;241m.\u001b[39mfit(x_train, y_train, epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, validation_data \u001b[38;5;241m=\u001b[39m (x_test,y_test),verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loaded_model' is not defined"
     ]
    }
   ],
   "source": [
    "# train up the top layer first\n",
    "\n",
    "model_2 = tf.keras.models.load_model('./saved_models/model_ROUND3')\n",
    "\n",
    "# for layer in model_2.layers:\n",
    "#     layer.trainable = False\n",
    "\n",
    "\n",
    "\n",
    "# recall = tf.keras.metrics.Recall()\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.01, decay=0.01)\n",
    "model_2.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model_2.fit(train_ds_1,\n",
    "                    validation_data=validation_ds_1,\n",
    "#                     class_weight=class_weights,\n",
    "                    epochs=20, callbacks=[callback,cp_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 0.9981\n",
      "Epoch 1: saving model to ../checkpoints/training_ROUND3_part2/cp.ckpt\n",
      "375/375 [==============================] - 27s 71ms/step - loss: 0.0079 - accuracy: 0.9981 - val_loss: 0.0669 - val_accuracy: 0.9817\n"
     ]
    }
   ],
   "source": [
    "history = model_2.fit(train_ds_1,\n",
    "                    validation_data=validation_ds_1,\n",
    "#                     class_weight=class_weights,\n",
    "                    epochs=1, callbacks=[callback,cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt = tf.keras.optimizers.Adam(0.1)\n",
    "# net = Net()\n",
    "# dataset = toy_dataset()\n",
    "# iterator = iter(dataset)\n",
    "# ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=optimizer, net=net, iterator=iterator)\n",
    "# manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=3)\n",
    "\n",
    "# train_and_checkpoint(net, manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train all the layers together for a bit with a much lower learning rate\n",
    "\n",
    "# for layer in base_model_2.layers[-20:]:\n",
    "#     if not isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "#         layer.trainable = True\n",
    "\n",
    "# recall = tf.keras.metrics.Recall()\n",
    "# optimizer = keras.optimizers.Adam(learning_rate=0.0004, decay=0.001)\n",
    "# model_2.compile(loss=\"categorical_crossentropy\", optimizer=optimizer,\n",
    "#               metrics=[\"accuracy\"])\n",
    "# history = model_2.fit(train_ds_1,\n",
    "#                     validation_data=validation_ds_1,\n",
    "# #                     class_weight=class_weights,\n",
    "#                     epochs=50, callbacks=[callback,cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train all the layers together for a bit with a much lower learning rate\n",
    "\n",
    "# for layer in base_model_2.layers[-20:]:\n",
    "#     if not isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "#         layer.trainable = True\n",
    "\n",
    "# recall = tf.keras.metrics.Recall()\n",
    "# optimizer = keras.optimizers.Adam(learning_rate=0.0004, decay=0.001)\n",
    "# model_2.compile(loss=\"categorical_crossentropy\", optimizer=optimizer,\n",
    "#               metrics=[\"accuracy\"])\n",
    "# history = model_2.fit(train_ds_1,\n",
    "#                     validation_data=validation_ds_1,\n",
    "# #                     class_weight=class_weights,\n",
    "#                     epochs=1, callbacks=[callback,cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/model_ROUND3_part2/assets\n"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "model_2.save('saved_models/model_ROUND3_part2') # change this path to save a new version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if you need to use the checkpoint, use this code\n",
    "# # source: https://www.tensorflow.org/tutorials/keras/save_and_load#checkpoint_callback_options\n",
    "\n",
    "# latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "# latest\n",
    "\n",
    "# # Create a new model instance\n",
    "# model_2 = create_model()\n",
    "\n",
    "# # Load the previously saved weights\n",
    "# model_2.load_weights(latest)\n",
    "\n",
    "# # Re-evaluate the model\n",
    "# loss, acc = model_2.evaluate(validation_ds_1 verbose=2)\n",
    "# print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Do:\n",
    "\n",
    "Oversampling/Data Augmentation:\n",
    "\n",
    "1. start a new file with clear labels, resampling, augmented data\n",
    "2. Train the model the same way\n",
    "3. Save model and create confusion matrix in this file (or seperate file)\n",
    "\n",
    "Prediction weights\n",
    "1. When predicting classes, change wieghts until we get 100% for covid cases\n",
    "2. Change to proportional CM instead of just numeric?\n",
    "\n",
    "Recall and F-score as metric?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow 2.8.0/Keras Py3.9",
   "language": "python",
   "name": "tensorflow-2.8.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
